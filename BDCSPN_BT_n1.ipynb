{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNY1hT8FR6QWG95LVPnwvCO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kazi-Rakib-Hasan-Jawwad/Histo-FSL/blob/master/BDCSPN_BT_n1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lTEdNFzZSZCL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import pytorch_lightning as pl\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "import os\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_encoder_weights(encoder, weights):\n",
        "    model_dict = encoder.state_dict()\n",
        "    weights = {k: v for k, v in weights.items() if k in model_dict}\n",
        "    if weights == {}:\n",
        "        print('No weight could be loaded..')\n",
        "    model_dict.update(weights)\n",
        "    encoder.load_state_dict(model_dict)\n",
        "    return encoder"
      ],
      "metadata": {
        "id": "Q3vk6tuNSdar"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model: torch.nn) -> None:\n",
        "    \"\"\"Print number of trainable parameters.\"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param}\"\n",
        "        f\" || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "YxORmW6KSgyi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "\n",
        "encoder = torchvision.models.__dict__['resnet50'](pretrained=False)\n",
        "path = \"/home/rakib/models/paper_benchmarking_ssl_diverse_pathology/bt_rn50_ep200.torch\"\n",
        "state_dict = torch.load(path, map_location='cuda:0')\n",
        "# state_dict = state['state_dict']\n",
        "encoder.fc = torch.nn.Identity()\n",
        "model = load_encoder_weights(encoder, state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d2YsFKQSjgh",
        "outputId": "1bf2a0c1-78a2-47e9-a276-c185e87344b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/rakib/project-6/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/rakib/project-6/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the base network to non-trainable (for speedup fine-tuning):\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "qoxLc88LSoJ7"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach a trainable linear layer to adapt to the new task:\n",
        "\n",
        "num_classes = 9  # Number of classes in the tuning dataset\n",
        "model.fc = torch.nn.Linear(2048, num_classes)\n",
        "#torch.nn.init.xavier_uniform_(model.fc.weight)"
      ],
      "metadata": {
        "id": "wu5oIfgkSrPu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from easyfsl.methods import BDCSPN\n",
        "\n",
        "net = BDCSPN(model)"
      ],
      "metadata": {
        "id": "Jqal8C91S5p5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_trainable_parameters(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOFo77mHTRKx",
        "outputId": "a81a4ab8-85ea-4d1d-f5d4-dabb2d675f47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 18441 || all params: 23526473 || trainable%: 0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from easyfsl.samplers import TaskSampler\n",
        "from easyfsl.datasets import FeaturesDataset, WrapFewShotDataset"
      ],
      "metadata": {
        "id": "8teMy04zTV2f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "\n",
        "# Instantiate the datasets\n",
        "train_path = Path(\"/home/rakib/data/NCT-CRC-Modified-81K/train/\")\n",
        "val_path = Path(\"/home/rakib/data/NCT-CRC-Modified-81K/val/\")\n",
        "\n",
        "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
        "                                    transforms.ToTensor()])\n",
        "val_transform = transforms.Compose([transforms.CenterCrop((224, 224)), transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(train_path, transform=train_transform)\n",
        "val_data = torchvision.datasets.ImageFolder(val_path, transform=val_transform)"
      ],
      "metadata": {
        "id": "6nUOOPInTowF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_way = 5\n",
        "n_shot = 6\n",
        "n_query = 10\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_workers = 12\n",
        "n_tasks_per_epoch = 100\n",
        "n_validation_tasks = 100"
      ],
      "metadata": {
        "id": "EAqkD6pvVMU2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = WrapFewShotDataset(train_data)\n",
        "val_set = WrapFewShotDataset(val_data)\n",
        "\n",
        "# Those are special batch samplers that sample few-shot classification tasks with a pre-defined shape\n",
        "train_sampler = TaskSampler(\n",
        "    train_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_tasks_per_epoch\n",
        ")\n",
        "val_sampler = TaskSampler(\n",
        "    val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks\n",
        ")\n",
        "\n",
        "# Finally, the DataLoader. We customize the collate_fn so that batches are delivered\n",
        "# in the shape: (support_images, support_labels, query_images, query_labels, class_ids)\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_sampler=train_sampler,\n",
        "    num_workers=n_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=train_sampler.episodic_collate_fn,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_set,\n",
        "    batch_sampler=val_sampler,\n",
        "    num_workers=n_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=val_sampler.episodic_collate_fn,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzem6DqHWCdo",
        "outputId": "8d18a5b9-88fc-4d6c-ef70-be54d7a19be0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scrolling dataset's labels...: 100%|█████| 63000/63000 [02:20<00:00, 449.28it/s]\n",
            "Scrolling dataset's labels...: 100%|█████| 15840/15840 [00:19<00:00, 799.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjK3uhJZaU7y",
        "outputId": "9a8aa3fd-4181-4f07-df7a-855ecd20c457"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BDCSPN(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=2048, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD, Optimizer\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 50\n",
        "#scheduler_milestones = [120, 160]\n",
        "#scheduler_gamma = 0.1\n",
        "#learning_rate = 1e-2\n",
        "tb_logs_dir = Path(\".\")\n",
        "'''\n",
        "train_optimizer = SGD(\n",
        "    net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4\n",
        ")\n",
        "train_scheduler = MultiStepLR(\n",
        "    train_optimizer,\n",
        "    milestones=scheduler_milestones,\n",
        "    gamma=scheduler_gamma,\n",
        ")\n",
        "\n",
        "tb_writer = SummaryWriter(log_dir=str(tb_logs_dir))\n",
        "'''\n",
        "train_optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
        "train_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=train_optimizer, T_max=20)\n",
        "\n",
        "tb_writer = SummaryWriter(log_dir=str(tb_logs_dir))"
      ],
      "metadata": {
        "id": "RQJJm8XkWcSv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from easyfsl.utils import evaluate\n",
        "from tqdm import tqdm\n",
        "from statistics import mean\n",
        "from easyfsl.methods import FewShotClassifier"
      ],
      "metadata": {
        "id": "nKGeGm1lXSnx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_epoch(\n",
        "    model: FewShotClassifier, data_loader: DataLoader, optimizer: Optimizer\n",
        "):\n",
        "    all_loss = []\n",
        "    model.train()\n",
        "    with tqdm(\n",
        "        enumerate(data_loader), total=len(data_loader), desc=\"Training\"\n",
        "    ) as tqdm_train:\n",
        "        for episode_index, (\n",
        "            support_images,\n",
        "            support_labels,\n",
        "            query_images,\n",
        "            query_labels,\n",
        "            _,\n",
        "        ) in tqdm_train:\n",
        "            optimizer.zero_grad()\n",
        "            model.process_support_set(\n",
        "                support_images.to(DEVICE), support_labels.to(DEVICE)\n",
        "            )\n",
        "            classification_scores = model(query_images.to(DEVICE))\n",
        "\n",
        "            loss = LOSS_FUNCTION(classification_scores, query_labels.to(DEVICE))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            all_loss.append(loss.item())\n",
        "\n",
        "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
        "\n",
        "    return mean(all_loss)"
      ],
      "metadata": {
        "id": "5zOFNRXpWyaL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_state = net.state_dict()\n",
        "best_validation_accuracy = 0.0\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    average_loss = training_epoch(net, train_loader, train_optimizer)\n",
        "    validation_accuracy = evaluate(\n",
        "        net, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
        "    )\n",
        "\n",
        "    if validation_accuracy > best_validation_accuracy:\n",
        "        best_validation_accuracy = validation_accuracy\n",
        "        best_state = copy.deepcopy(net.state_dict())\n",
        "        # state_dict() returns a reference to the still evolving model's state so we deepcopy\n",
        "        # https://pytorch.org/tutorials/beginner/saving_loading_models\n",
        "        print(\"Ding ding ding! We found a new best model!\")\n",
        "\n",
        "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
        "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
        "\n",
        "    # Warn the scheduler that we did an epoch\n",
        "    # so it knows when to decrease the learning rate\n",
        "    train_scheduler.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ5W_i0rW231",
        "outputId": "2e2e8c13-62ba-4c0f-c525-1fdb4902009f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|████████████████████| 100/100 [00:08<00:00, 12.16it/s, loss=0.93]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.51it/s, accuracy=0.956]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.31it/s, loss=0.892]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.65it/s, accuracy=0.966]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|███████████████████| 100/100 [00:07<00:00, 12.54it/s, loss=0.888]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 14.11it/s, accuracy=0.967]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|███████████████████| 100/100 [00:07<00:00, 12.80it/s, loss=0.867]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.75it/s, accuracy=0.974]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:07<00:00, 12.88it/s, loss=0.868]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.00it/s, accuracy=0.977]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.25it/s, loss=0.866]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 14.19it/s, accuracy=0.978]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.62it/s, loss=0.857]\n",
            "Validation: 100%|██████████████| 100/100 [00:07<00:00, 13.18it/s, accuracy=0.98]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.25it/s, loss=0.857]\n",
            "Validation: 100%|██████████████| 100/100 [00:07<00:00, 13.18it/s, accuracy=0.98]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.62it/s, loss=0.862]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.07it/s, accuracy=0.983]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.85it/s, loss=0.857]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.94it/s, accuracy=0.981]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.89it/s, loss=0.851]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.19it/s, accuracy=0.979]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|████████████████████| 100/100 [00:08<00:00, 11.97it/s, loss=0.85]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.96it/s, accuracy=0.978]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.87it/s, loss=0.848]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.31it/s, accuracy=0.983]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.94it/s, loss=0.846]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.18it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.72it/s, loss=0.849]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.05it/s, accuracy=0.981]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.43it/s, loss=0.844]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.16it/s, accuracy=0.983]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.38it/s, loss=0.846]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.38it/s, accuracy=0.982]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.15it/s, loss=0.847]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.13it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.87it/s, loss=0.844]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.08it/s, accuracy=0.983]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.86it/s, loss=0.845]\n",
            "Validation: 100%|██████████████| 100/100 [00:07<00:00, 12.97it/s, accuracy=0.98]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.98it/s, loss=0.844]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.70it/s, accuracy=0.981]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.74it/s, loss=0.847]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.13it/s, accuracy=0.982]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.99it/s, loss=0.842]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.91it/s, accuracy=0.977]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|████████████████████| 100/100 [00:08<00:00, 11.90it/s, loss=0.85]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.92it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.84it/s, loss=0.844]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.92it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.64it/s, loss=0.842]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.23it/s, accuracy=0.987]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.76it/s, loss=0.845]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.16it/s, accuracy=0.981]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.83it/s, loss=0.848]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.95it/s, accuracy=0.985]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.69it/s, loss=0.841]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.08it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.04it/s, loss=0.844]\n",
            "Validation: 100%|██████████████| 100/100 [00:07<00:00, 13.15it/s, accuracy=0.98]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.13it/s, loss=0.845]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.17it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.11it/s, loss=0.842]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.23it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.07it/s, loss=0.843]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.13it/s, accuracy=0.983]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.13it/s, loss=0.844]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.24it/s, accuracy=0.981]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.84it/s, loss=0.843]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.07it/s, accuracy=0.979]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.99it/s, loss=0.845]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.02it/s, accuracy=0.981]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|████████████████████| 100/100 [00:08<00:00, 11.79it/s, loss=0.84]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.28it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.90it/s, loss=0.841]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.14it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.19it/s, loss=0.841]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.09it/s, accuracy=0.987]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.91it/s, loss=0.842]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.03it/s, accuracy=0.985]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.98it/s, loss=0.839]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.15it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.18it/s, loss=0.836]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.06it/s, accuracy=0.982]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.23it/s, loss=0.838]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.08it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.08it/s, loss=0.837]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.07it/s, accuracy=0.987]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.95it/s, loss=0.836]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.08it/s, accuracy=0.988]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.99it/s, loss=0.833]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.04it/s, accuracy=0.985]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.19it/s, loss=0.838]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.10it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.92it/s, loss=0.834]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.25it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.12it/s, loss=0.835]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.05it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.90it/s, loss=0.831]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.14it/s, accuracy=0.982]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.load_state_dict(best_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNEMXT7kYSDc",
        "outputId": "42d894e9-ec32-4f87-affa-3ee935f6989c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the datasets\n",
        "test_path = Path(\"/home/rakib/data/CRC-VAL-HE-7K/\")\n",
        "\n",
        "test_data = torchvision.datasets.ImageFolder(test_path, transform=val_transform)\n",
        "\n",
        "test_set = WrapFewShotDataset(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0emKDKWacQgW",
        "outputId": "de541f13-933e-45cc-e04c-a3116d4fb80d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scrolling dataset's labels...: 100%|███████| 7180/7180 [00:12<00:00, 554.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_test_tasks = 5000"
      ],
      "metadata": {
        "id": "crq7I9j_foSv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sampler = TaskSampler(\n",
        "    test_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_test_tasks\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_sampler=test_sampler,\n",
        "    num_workers=n_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=test_sampler.episodic_collate_fn,\n",
        ")"
      ],
      "metadata": {
        "id": "-A0SiQR-cLmk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate(net, test_loader, device=DEVICE)\n",
        "print(f\"Average accuracy : {(100 * accuracy):.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyXyPASfdJDw",
        "outputId": "095ab635-da8f-4804-e71e-4f031afd67ee"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████| 5000/5000 [05:35<00:00, 14.91it/s, accuracy=0.967]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy : 96.66 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = load_encoder_weights(encoder, state_dict)"
      ],
      "metadata": {
        "id": "a668JwrWlN2o"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(test_data, batch_size=1, shuffle=False, drop_last=False)\n",
        "data_labels = np.zeros(shape=(0))\n",
        "embeddings = np.zeros(shape=(0, 2048))\n",
        "for x, y in iter(dataloader):\n",
        "    x = x.to(DEVICE)\n",
        "    pred = net(x)\n",
        ""
      ],
      "metadata": {
        "id": "n30RjY_2gDuG"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: find shape of pred\n",
        "\n",
        "print(pred.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIoaRNk6kNVx",
        "outputId": "61f5a17c-3d31-41c4-f8ea-2fb412d141db"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixS_zdmum7kH",
        "outputId": "2e621313-1825-41fe-c6ee-e334169fd093"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1396, -0.1177,  0.0492, -0.3430,  0.9620]], device='cuda:0',\n",
            "       grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the base network to non-trainable (for speedup fine-tuning):\n",
        "\n",
        "for param in model2.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "zVXTPTpirQ4G"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 9  # Number of classes in the tuning dataset\n",
        "model2.fc = torch.nn.Linear(2048, num_classes)"
      ],
      "metadata": {
        "id": "CXp6B-HirawF"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from easyfsl.methods import SimpleShot\n",
        "net2 = SimpleShot(model2)"
      ],
      "metadata": {
        "id": "Nc5TunO8q8vd"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O10qzmjyr9sy",
        "outputId": "8e5cd8b4-74c5-4e54-ae79-21fb6623faa6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleShot(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=2048, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_optimizer2 = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
        "train_scheduler2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=train_optimizer, T_max=20)\n",
        "\n",
        "best_state2 = net2.state_dict()\n",
        "best_validation_accuracy = 0.0\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    average_loss = training_epoch(net2, train_loader, train_optimizer2)\n",
        "    validation_accuracy = evaluate(\n",
        "        net2, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
        "    )\n",
        "\n",
        "    if validation_accuracy > best_validation_accuracy:\n",
        "        best_validation_accuracy = validation_accuracy\n",
        "        best_state2 = copy.deepcopy(net2.state_dict())\n",
        "        # state_dict() returns a reference to the still evolving model's state so we deepcopy\n",
        "        # https://pytorch.org/tutorials/beginner/saving_loading_models\n",
        "        print(\"Ding ding ding! We found a new best model!\")\n",
        "\n",
        "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
        "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
        "\n",
        "    # Warn the scheduler that we did an epoch\n",
        "    # so it knows when to decrease the learning rate\n",
        "    train_scheduler2.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU1bu0WEroLU",
        "outputId": "9fd7e0f7-759e-45c5-a944-0d517cc2ccb7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|████████████████████| 100/100 [00:08<00:00, 11.65it/s, loss=1.08]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.74it/s, accuracy=0.952]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/home/rakib/project-6/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.76it/s, loss=0.889]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.65it/s, accuracy=0.963]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.44it/s, loss=0.868]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.36it/s, accuracy=0.978]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.21it/s, loss=0.863]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.43it/s, accuracy=0.978]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|████████████████████| 100/100 [00:08<00:00, 11.47it/s, loss=0.86]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.41it/s, accuracy=0.979]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.78it/s, loss=0.855]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.49it/s, accuracy=0.981]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.53it/s, loss=0.857]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.29it/s, accuracy=0.979]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.25it/s, loss=0.856]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.39it/s, accuracy=0.981]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:09<00:00, 10.03it/s, loss=0.854]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.01it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|████████████████████| 100/100 [00:11<00:00,  8.51it/s, loss=0.85]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.06it/s, accuracy=0.985]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:11<00:00,  8.78it/s, loss=0.845]\n",
            "Validation: 100%|██████████████| 100/100 [00:07<00:00, 12.56it/s, accuracy=0.98]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.35it/s, loss=0.851]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.23it/s, accuracy=0.985]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.47it/s, loss=0.846]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.42it/s, accuracy=0.985]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.62it/s, loss=0.843]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.53it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.50it/s, loss=0.843]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.48it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.81it/s, loss=0.842]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.36it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.53it/s, loss=0.846]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.33it/s, accuracy=0.988]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|████████████████████| 100/100 [00:08<00:00, 11.82it/s, loss=0.84]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.32it/s, accuracy=0.988]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.59it/s, loss=0.838]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.48it/s, accuracy=0.983]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.56it/s, loss=0.847]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.42it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.38it/s, loss=0.836]\n",
            "Validation: 100%|██████████████| 100/100 [00:08<00:00, 12.28it/s, accuracy=0.98]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.54it/s, loss=0.843]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.30it/s, accuracy=0.983]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.30it/s, loss=0.839]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.41it/s, accuracy=0.982]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.33it/s, loss=0.839]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.31it/s, accuracy=0.992]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.71it/s, loss=0.844]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.21it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.58it/s, loss=0.839]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.09it/s, accuracy=0.989]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.41it/s, loss=0.841]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.42it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.39it/s, loss=0.834]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.59it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.47it/s, loss=0.837]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.93it/s, accuracy=0.989]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|████████████████████| 100/100 [00:08<00:00, 11.94it/s, loss=0.83]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.48it/s, accuracy=0.987]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.03it/s, loss=0.834]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.23it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.23it/s, loss=0.834]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.04it/s, accuracy=0.984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.31it/s, loss=0.836]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.26it/s, accuracy=0.989]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.03it/s, loss=0.832]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.35it/s, accuracy=0.985]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.21it/s, loss=0.831]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.27it/s, accuracy=0.985]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.46it/s, loss=0.837]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.99it/s, accuracy=0.987]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.27it/s, loss=0.836]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.06it/s, accuracy=0.989]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.37it/s, loss=0.834]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.61it/s, accuracy=0.987]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.75it/s, loss=0.832]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.06it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.90it/s, loss=0.836]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.76it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.39it/s, loss=0.835]\n",
            "Validation: 100%|██████████████| 100/100 [00:07<00:00, 12.85it/s, accuracy=0.99]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.14it/s, loss=0.827]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.02it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.20it/s, loss=0.837]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.27it/s, accuracy=0.988]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.88it/s, loss=0.835]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.92it/s, accuracy=0.987]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.19it/s, loss=0.833]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.94it/s, accuracy=0.988]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.42it/s, loss=0.833]\n",
            "Validation: 100%|█████████████| 100/100 [00:08<00:00, 12.41it/s, accuracy=0.988]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.69it/s, loss=0.834]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.56it/s, accuracy=0.989]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.14it/s, loss=0.833]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.71it/s, accuracy=0.987]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 11.62it/s, loss=0.828]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 12.74it/s, accuracy=0.986]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|███████████████████| 100/100 [00:08<00:00, 12.31it/s, loss=0.833]\n",
            "Validation: 100%|█████████████| 100/100 [00:07<00:00, 13.33it/s, accuracy=0.988]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate(net2, test_loader, device=DEVICE)\n",
        "print(f\"Average accuracy : {(100 * accuracy):.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oh2GUKIsKlc",
        "outputId": "b21f8f72-55a2-47b8-db39-56c414a27b50"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████| 5000/5000 [05:28<00:00, 15.22it/s, accuracy=0.961]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy : 96.06 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}