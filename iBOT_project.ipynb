{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZuseQGnpNUC1xmxOg7ZeM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f74e716f447c4c7e808cfed801a70329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39e3cc882eec41d293edcc6def7a6c19",
              "IPY_MODEL_1753799df4944f629ab67ff2393d53ea",
              "IPY_MODEL_b70bf35c093947faa08af2524b9c76c5"
            ],
            "layout": "IPY_MODEL_44bae7b082744836a4358a75fcf3a49c",
            "tabbable": null,
            "tooltip": null
          }
        },
        "39e3cc882eec41d293edcc6def7a6c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9a8d20a943f34b0c9ce08fd93062e29c",
            "placeholder": "​",
            "style": "IPY_MODEL_2004a5ffd8614995baecd05f8231d327",
            "tabbable": null,
            "tooltip": null,
            "value": "Resolving data files: 100%"
          }
        },
        "1753799df4944f629ab67ff2393d53ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c1f7ce8a424f465d9f0d8cfa584e3edd",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a84f6379cf241989b79430f8a730a99",
            "tabbable": null,
            "tooltip": null,
            "value": 100000
          }
        },
        "b70bf35c093947faa08af2524b9c76c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_edaf8964257a4c4b847fdc33627ebfdc",
            "placeholder": "​",
            "style": "IPY_MODEL_d1669ce6f92843ea966a4a8690c5fa7f",
            "tabbable": null,
            "tooltip": null,
            "value": " 100000/100000 [00:00&lt;00:00, 217285.33it/s]"
          }
        },
        "44bae7b082744836a4358a75fcf3a49c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8d20a943f34b0c9ce08fd93062e29c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2004a5ffd8614995baecd05f8231d327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c1f7ce8a424f465d9f0d8cfa584e3edd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a84f6379cf241989b79430f8a730a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edaf8964257a4c4b847fdc33627ebfdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1669ce6f92843ea966a4a8690c5fa7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "8ff42b5332b8452da3404c1485667f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f455feee0b845f3a2c7f20afb7a1127",
              "IPY_MODEL_12912d2262b54d16b6c9f93c26197978",
              "IPY_MODEL_0fc61da438994b6e8af0c9608a1b7681"
            ],
            "layout": "IPY_MODEL_8295e260fd8b404b8ad4f459f1f7fe25",
            "tabbable": null,
            "tooltip": null
          }
        },
        "3f455feee0b845f3a2c7f20afb7a1127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_684089a185794b8b8664f2100d1f1127",
            "placeholder": "​",
            "style": "IPY_MODEL_38fd34e0c8814e048a72ee1414f60f81",
            "tabbable": null,
            "tooltip": null,
            "value": "Resolving data files: 100%"
          }
        },
        "12912d2262b54d16b6c9f93c26197978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4b259235555e4cad9c0fca393e79af06",
            "max": 7180,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5c02905d9a64ab0bcc5e2fcb306ffaf",
            "tabbable": null,
            "tooltip": null,
            "value": 7180
          }
        },
        "0fc61da438994b6e8af0c9608a1b7681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_661b933330de482fb9a48aef8061de7b",
            "placeholder": "​",
            "style": "IPY_MODEL_0c75697ac16f4d1798d93bb88ce6b609",
            "tabbable": null,
            "tooltip": null,
            "value": " 7180/7180 [00:00&lt;00:00,  6.81it/s]"
          }
        },
        "8295e260fd8b404b8ad4f459f1f7fe25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684089a185794b8b8664f2100d1f1127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38fd34e0c8814e048a72ee1414f60f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4b259235555e4cad9c0fca393e79af06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c02905d9a64ab0bcc5e2fcb306ffaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "661b933330de482fb9a48aef8061de7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c75697ac16f4d1798d93bb88ce6b609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kazi-Rakib-Hasan-Jawwad/Histo-FSL/blob/master/iBOT_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps to connect Colab with local runtime:\n",
        "1. Put this command in virtual environment terminal:\n",
        "\n",
        "> jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0\n",
        "\n",
        "2. Copy and paste the url in colab.\n",
        "\n",
        "\n",
        "Check availability of GPU."
      ],
      "metadata": {
        "id": "QbGpN-OoBA7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WolzVH9Y24Db",
        "outputId": "6e7b1236-f266-4d90-a69f-b0db492da276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__CUDNN VERSION: 8500\n",
            "__Number CUDA Devices: 1\n",
            "__CUDA Device Name: NVIDIA GeForce RTX 3080 Ti\n",
            "__CUDA Device Total Memory [GB]: 12.636192768\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
        "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
        "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PnBq8NhvC1UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "working_directory = Path(\"/home/rakib/jupyter_notebooks/iBOT_project\")\n",
        "cache_dir = working_directory / \"cache\""
      ],
      "metadata": {
        "id": "xTl9SNStCyjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# We first download custom scripts from Hugging Face\n",
        "for script in [\"data\", \"module\", \"trainer\", \"utils\"]:\n",
        "    data_file = hf_hub_download(\n",
        "        repo_id=\"owkin/camelyon16-features\",\n",
        "        filename=f\"scripts/{script}.py\",\n",
        "        repo_type=\"dataset\",\n",
        "        cache_dir=cache_dir\n",
        "    )\n",
        "\n",
        "  # The data script handles data loading\n",
        "  # Module loads the Chowder model to make predictions (described after)\n",
        "  # Trainer is responsible for updating the model based on data batches\n",
        "  # Utils is a set of utility functions\n",
        "\n",
        "# Using sys.path.append, we enable the import of functions inside\n",
        "# the python scripts we just downloaded\n",
        "scripts_dir = Path(data_file).parent\n",
        "sys.path.append(str(scripts_dir))"
      ],
      "metadata": {
        "id": "jPI9BVxzDv-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from data import SlideFeaturesDataset\n",
        "\n",
        "# ``SlideFeaturesDataset`` is used to first download the data from\n",
        "# Hugging Face, then create a proper torch dataset inherited\n",
        "# from ``torch.utils.data.Dataset` class. The ``__getitem__```\n",
        "# function of this dataset returns (X, y). X is a matrix\n",
        "# of features for the slide with dimension (1000, 768). 1000\n",
        "# corresponds to the number of features (i.e. number of tiles)\n",
        "# sampled from the given slide, while 768 is the dimension of\n",
        "# the features (i.e. the output dimension of Phikon).\n",
        "# y is the label (0 or 1 for absence or presence of metastasis).\n",
        "\n",
        "# ``cam16_design_dataset`` contains 269 WSIs\n",
        "cam16_design_dataset = SlideFeaturesDataset(\n",
        "    \"owkin/camelyon16-features\",\n",
        "    split=\"Phikon_train\",\n",
        "    cache_dir=cache_dir\n",
        ")\n",
        "\n",
        "# ``cam16_test_dataset`` contains 130 WSIs\n",
        "cam16_test_dataset = SlideFeaturesDataset(\n",
        "    \"owkin/camelyon16-features\",\n",
        "    split=\"Phikon_test\",\n",
        "    cache_dir=cache_dir\n",
        ")\n",
        "\n",
        "# We store the indices and labels of the whole training dataset\n",
        "# for cross-validation\n",
        "cam16_design_indices = np.arange(len(cam16_design_dataset))\n",
        "cam16_design_labels = cam16_design_dataset.labels"
      ],
      "metadata": {
        "id": "NLN2KrAgEHiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from module import Chowder\n",
        "\n",
        "chowder = Chowder(\n",
        "    in_features=768,                     # output dimension of Phikon\n",
        "    out_features=1,                      # dimension of predictions (a probability for class \"1\")\n",
        "    n_top=5,                             # number of top scores in Chowder (in the image, N is 2)\n",
        "    n_bottom=5,                          # number of bottom scores in Chowder\n",
        "    mlp_hidden=[200, 100],               # MLP hidden layers after the max-min layer\n",
        "    mlp_activation=torch.nn.Sigmoid(),   # MLP activation\n",
        "    bias=True                            # bias for first 1D convolution which computes scores\n",
        ")\n",
        "\n",
        "def print_trainable_parameters(model: torch.nn) -> None:\n",
        "    \"\"\"Print number of trainable parameters.\"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param}\"\n",
        "        f\" || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "    )\n",
        "\n",
        "# Chowder has 23,170 parameters: it's a very small model !\n",
        "print_trainable_parameters(chowder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmEJ6MvkMFhT",
        "outputId": "9af40a71-1b1d-4cbf-bc46-b84224aa93ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 23170 || all params: 23170 || trainable%: 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import auc, pad_collate_fn\n",
        "\n",
        "# We define the loss function, optimizer and metrics for the training\n",
        "criterion = torch.nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
        "optimizer = torch.optim.Adam              # Adam optimizer\n",
        "metrics = {\"auc\": auc}                    # AUC will be the tracking metric\n",
        "\n",
        "# ``collator`` is a function that apply a deterministic\n",
        "# transformation to a batch of samples before being processed\n",
        "# by the GPU. Here, this function is ``pad_collate_fn``. The\n",
        "# goal of this function is align matrices of features (the inputs)\n",
        "# in terms of shape. Indeed, some WSI may have 200 features (very\n",
        "# small piece of tissues) or 1,000 (the maximum we set). In that case,\n",
        "# all matrices will have a shape of at most the bigger matrices in the\n",
        "# batch. Our (200, 768) input matrix will become a (1000, 768) matrix\n",
        "# with 800 ``inf`` values. A boolean mask is stored so that to tell\n",
        "# torch not to process these 800 values but only focus on the 200 real ones\n",
        "\n",
        "collator = pad_collate_fn\n"
      ],
      "metadata": {
        "id": "u5Ja04FeMUoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from copy import deepcopy\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from trainer import TorchTrainer, slide_level_train_step, slide_level_val_step\n",
        "\n",
        "# We run a 5-fold cross-validation with 1 repeat (you can tweak these parameters)\n",
        "n_repeats = 1\n",
        "n_folds = 5\n",
        "train_metrics, val_metrics = [], []\n",
        "test_logits = []\n",
        "\n",
        "cv_start_time = datetime.now()\n",
        "\n",
        "for repeat in range(n_repeats):\n",
        "    print(f\"Running cross-validation #{repeat+1}\")\n",
        "    # We stratify with respect to the training labels\n",
        "    cv_skfold = StratifiedKFold(\n",
        "        n_splits=n_folds,\n",
        "        shuffle=True,\n",
        "        random_state=repeat,\n",
        "    )\n",
        "    cv_splits = cv_skfold.split(cam16_design_indices, y=cam16_design_labels)\n",
        "\n",
        "    # 1 training fold approximately takes 25 seconds\n",
        "    for i, (train_indices, val_indices) in enumerate(cv_splits):\n",
        "        fold_start_time = datetime.now()\n",
        "        trainer = TorchTrainer(\n",
        "            model=deepcopy(chowder),\n",
        "            criterion=criterion,\n",
        "            metrics=metrics,\n",
        "            batch_size=16,                           # you can tweak this\n",
        "            num_epochs=15,                           # you can tweak this\n",
        "            learning_rate=1e-3,                      # you can tweak this\n",
        "            weight_decay=0.0,                        # you can tweak this\n",
        "            device=\"cuda:0\",\n",
        "            num_workers=multiprocessing.cpu_count(), # you can tweak this\n",
        "            optimizer=deepcopy(optimizer),\n",
        "            train_step=slide_level_train_step,\n",
        "            val_step=slide_level_val_step,\n",
        "            collator=pad_collate_fn,\n",
        "        )\n",
        "\n",
        "        print(f\"Running cross-validation on split #{i+1}\")\n",
        "        cam16_train_dataset = torch.utils.data.Subset(\n",
        "            cam16_design_dataset, indices=train_indices\n",
        "        )\n",
        "        cam16_val_dataset = torch.utils.data.Subset(\n",
        "            cam16_design_dataset, indices=val_indices\n",
        "        )\n",
        "\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "            # Training step for the given number of epochs\n",
        "            local_train_metrics, local_val_metrics = trainer.train(\n",
        "                cam16_train_dataset, cam16_val_dataset\n",
        "            )\n",
        "            # Predictions on test (logits, sigmoid(logits) = probability)\n",
        "            local_test_logits = trainer.predict(cam16_test_dataset)[1]\n",
        "\n",
        "        train_metrics.append(local_train_metrics)\n",
        "        val_metrics.append(local_val_metrics)\n",
        "        test_logits.append(local_test_logits)\n",
        "        fold_end_time = datetime.now()\n",
        "        fold_running_time = fold_end_time - fold_start_time\n",
        "        print(\"\\n-----------------------------Finished in {}---------------------------------------\\n\".format(fold_running_time))\n",
        "    #clear_output()\n",
        "cv_end_time = datetime.now()\n",
        "cv_running_time = cv_end_time - cv_start_time\n",
        "print(\"\\nFinished cross-validation in {}\".format(cv_running_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PXi6sncMcAT",
        "outputId": "6002e44f-8a47-4c36-9c0d-75b506469c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running cross-validation #1\n",
            "Running cross-validation on split #1\n",
            "Epoch 1: train_loss=0.70871, train_auc=0.4995, val_loss=0.64457, val_auc=0.5028\n",
            "Epoch 2: train_loss=0.69223, train_auc=0.4939, val_loss=0.64451, val_auc=0.5142\n",
            "Epoch 3: train_loss=0.68629, train_auc=0.4952, val_loss=0.64741, val_auc=0.5455\n",
            "Epoch 4: train_loss=0.67597, train_auc=0.5329, val_loss=0.67830, val_auc=0.5810\n",
            "Epoch 5: train_loss=0.66828, train_auc=0.6040, val_loss=0.63151, val_auc=0.6264\n",
            "Epoch 6: train_loss=0.62713, train_auc=0.7494, val_loss=0.59019, val_auc=0.8111\n",
            "Epoch 7: train_loss=0.53927, train_auc=0.9172, val_loss=0.49161, val_auc=0.9205\n",
            "Epoch 8: train_loss=0.42296, train_auc=0.9301, val_loss=0.36481, val_auc=0.9446\n",
            "Epoch 9: train_loss=0.32791, train_auc=0.9474, val_loss=0.31733, val_auc=0.9375\n",
            "Epoch 10: train_loss=0.27063, train_auc=0.9557, val_loss=0.26647, val_auc=0.9531\n",
            "Epoch 11: train_loss=0.25160, train_auc=0.9589, val_loss=0.24450, val_auc=0.9560\n",
            "Epoch 12: train_loss=0.23698, train_auc=0.9615, val_loss=0.27657, val_auc=0.9702\n",
            "Epoch 13: train_loss=0.21839, train_auc=0.9682, val_loss=0.20466, val_auc=0.9716\n",
            "Epoch 14: train_loss=0.22252, train_auc=0.9660, val_loss=0.21170, val_auc=0.9673\n",
            "Epoch 15: train_loss=0.20335, train_auc=0.9699, val_loss=0.26179, val_auc=0.9773\n",
            "\n",
            "-----------------------------Finished in 0:00:33.824653---------------------------------------\n",
            "\n",
            "Running cross-validation on split #2\n",
            "Epoch 1: train_loss=0.70316, train_auc=0.4943, val_loss=0.64759, val_auc=0.4560\n",
            "Epoch 2: train_loss=0.67652, train_auc=0.5202, val_loss=0.65075, val_auc=0.5568\n",
            "Epoch 3: train_loss=0.68285, train_auc=0.5116, val_loss=0.67497, val_auc=0.5696\n",
            "Epoch 4: train_loss=0.66976, train_auc=0.5519, val_loss=0.64047, val_auc=0.5724\n",
            "Epoch 5: train_loss=0.68940, train_auc=0.5348, val_loss=0.67244, val_auc=0.5980\n",
            "Epoch 6: train_loss=0.66386, train_auc=0.6730, val_loss=0.62969, val_auc=0.6619\n",
            "Epoch 7: train_loss=0.62499, train_auc=0.7714, val_loss=0.61355, val_auc=0.7358\n",
            "Epoch 8: train_loss=0.56689, train_auc=0.8581, val_loss=0.54374, val_auc=0.8224\n",
            "Epoch 9: train_loss=0.46618, train_auc=0.9312, val_loss=0.48882, val_auc=0.8651\n",
            "Epoch 10: train_loss=0.35595, train_auc=0.9492, val_loss=0.40186, val_auc=0.8750\n",
            "Epoch 11: train_loss=0.27349, train_auc=0.9612, val_loss=0.38910, val_auc=0.8807\n",
            "Epoch 12: train_loss=0.23602, train_auc=0.9676, val_loss=0.37107, val_auc=0.8991\n",
            "Epoch 13: train_loss=0.20916, train_auc=0.9724, val_loss=0.35834, val_auc=0.8963\n",
            "Epoch 14: train_loss=0.17808, train_auc=0.9807, val_loss=0.35028, val_auc=0.9034\n",
            "Epoch 15: train_loss=0.15019, train_auc=0.9878, val_loss=0.35328, val_auc=0.9062\n",
            "\n",
            "-----------------------------Finished in 0:00:32.109814---------------------------------------\n",
            "\n",
            "Running cross-validation on split #3\n",
            "Epoch 1: train_loss=0.69696, train_auc=0.4570, val_loss=0.66266, val_auc=0.6293\n",
            "Epoch 2: train_loss=0.68181, train_auc=0.5009, val_loss=0.64213, val_auc=0.6193\n",
            "Epoch 3: train_loss=0.67811, train_auc=0.5586, val_loss=0.66754, val_auc=0.6733\n",
            "Epoch 4: train_loss=0.67770, train_auc=0.5325, val_loss=0.64099, val_auc=0.6804\n",
            "Epoch 5: train_loss=0.67254, train_auc=0.5992, val_loss=0.65631, val_auc=0.7784\n",
            "Epoch 6: train_loss=0.65457, train_auc=0.6293, val_loss=0.59882, val_auc=0.8807\n",
            "Epoch 7: train_loss=0.58918, train_auc=0.8498, val_loss=0.51172, val_auc=0.9474\n",
            "Epoch 8: train_loss=0.49705, train_auc=0.8929, val_loss=0.44122, val_auc=0.9673\n",
            "Epoch 9: train_loss=0.39036, train_auc=0.9208, val_loss=0.30176, val_auc=0.9730\n",
            "Epoch 10: train_loss=0.30378, train_auc=0.9504, val_loss=0.24969, val_auc=0.9730\n",
            "Epoch 11: train_loss=0.25392, train_auc=0.9609, val_loss=0.21683, val_auc=0.9730\n",
            "Epoch 12: train_loss=0.24214, train_auc=0.9584, val_loss=0.19523, val_auc=0.9773\n",
            "Epoch 13: train_loss=0.21974, train_auc=0.9692, val_loss=0.18141, val_auc=0.9787\n",
            "Epoch 14: train_loss=0.20437, train_auc=0.9744, val_loss=0.18540, val_auc=0.9801\n",
            "Epoch 15: train_loss=0.18613, train_auc=0.9797, val_loss=0.18182, val_auc=0.9815\n",
            "\n",
            "-----------------------------Finished in 0:00:32.079518---------------------------------------\n",
            "\n",
            "Running cross-validation on split #4\n",
            "Epoch 1: train_loss=0.69222, train_auc=0.4799, val_loss=0.65313, val_auc=0.6151\n",
            "Epoch 2: train_loss=0.68240, train_auc=0.4302, val_loss=0.64836, val_auc=0.6392\n",
            "Epoch 3: train_loss=0.68262, train_auc=0.4830, val_loss=0.64502, val_auc=0.6790\n",
            "Epoch 4: train_loss=0.68174, train_auc=0.4656, val_loss=0.63764, val_auc=0.7571\n",
            "Epoch 5: train_loss=0.66130, train_auc=0.6469, val_loss=0.62584, val_auc=0.8452\n",
            "Epoch 6: train_loss=0.61623, train_auc=0.8321, val_loss=0.55231, val_auc=0.9290\n",
            "Epoch 7: train_loss=0.52880, train_auc=0.9075, val_loss=0.43350, val_auc=0.9347\n",
            "Epoch 8: train_loss=0.39043, train_auc=0.9453, val_loss=0.32853, val_auc=0.9332\n",
            "Epoch 9: train_loss=0.30986, train_auc=0.9582, val_loss=0.33426, val_auc=0.9304\n",
            "Epoch 10: train_loss=0.27564, train_auc=0.9429, val_loss=0.27907, val_auc=0.9261\n",
            "Epoch 11: train_loss=0.23110, train_auc=0.9675, val_loss=0.27205, val_auc=0.9261\n",
            "Epoch 12: train_loss=0.21447, train_auc=0.9685, val_loss=0.30452, val_auc=0.9205\n",
            "Epoch 13: train_loss=0.18555, train_auc=0.9785, val_loss=0.28334, val_auc=0.9233\n",
            "Epoch 14: train_loss=0.15920, train_auc=0.9857, val_loss=0.27401, val_auc=0.9205\n",
            "Epoch 15: train_loss=0.16159, train_auc=0.9846, val_loss=0.29738, val_auc=0.9205\n",
            "\n",
            "-----------------------------Finished in 0:00:31.968891---------------------------------------\n",
            "\n",
            "Running cross-validation on split #5\n",
            "Epoch 1: train_loss=0.69630, train_auc=0.4876, val_loss=0.64967, val_auc=0.6437\n",
            "Epoch 2: train_loss=0.70909, train_auc=0.4543, val_loss=0.66017, val_auc=0.6261\n",
            "Epoch 3: train_loss=0.67360, train_auc=0.5029, val_loss=0.64638, val_auc=0.6510\n",
            "Epoch 4: train_loss=0.68119, train_auc=0.5292, val_loss=0.65359, val_auc=0.6217\n",
            "Epoch 5: train_loss=0.67744, train_auc=0.5248, val_loss=0.64059, val_auc=0.6290\n",
            "Epoch 6: train_loss=0.65988, train_auc=0.6568, val_loss=0.63291, val_auc=0.6979\n",
            "Epoch 7: train_loss=0.63766, train_auc=0.7081, val_loss=0.58895, val_auc=0.8563\n",
            "Epoch 8: train_loss=0.55478, train_auc=0.8473, val_loss=0.48384, val_auc=0.8915\n",
            "Epoch 9: train_loss=0.46050, train_auc=0.8985, val_loss=0.38645, val_auc=0.9267\n",
            "Epoch 10: train_loss=0.35322, train_auc=0.9443, val_loss=0.29981, val_auc=0.9370\n",
            "Epoch 11: train_loss=0.29865, train_auc=0.9529, val_loss=0.26572, val_auc=0.9457\n",
            "Epoch 12: train_loss=0.25376, train_auc=0.9622, val_loss=0.23797, val_auc=0.9457\n",
            "Epoch 13: train_loss=0.22991, train_auc=0.9686, val_loss=0.22270, val_auc=0.9487\n",
            "Epoch 14: train_loss=0.21156, train_auc=0.9736, val_loss=0.21324, val_auc=0.9472\n",
            "Epoch 15: train_loss=0.19729, train_auc=0.9761, val_loss=0.20757, val_auc=0.9516\n",
            "\n",
            "-----------------------------Finished in 0:00:31.856115---------------------------------------\n",
            "\n",
            "\n",
            "Finished cross-validation in 0:02:41.840876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import get_cv_metrics, roc_auc_score\n",
        "\n",
        "cv_train_metrics = get_cv_metrics(train_metrics)\n",
        "cv_val_metrics = get_cv_metrics(val_metrics)\n",
        "test_metrics = trainer.evaluate(cam16_test_dataset)\n",
        "\n",
        "print(\"Cross-validation results:\")\n",
        "for k, v in cv_train_metrics.items():\n",
        "    print(f\"mean_train_{k}: {v}\")\n",
        "\n",
        "for k, v in cv_val_metrics.items():\n",
        "    print(f\"mean_val_{k}: {v}\")\n",
        "\n",
        "print(\"\\nEnsembling results on test set:\")\n",
        "test_auc = roc_auc_score(\n",
        "    cam16_test_dataset.labels,\n",
        "    np.mean(test_logits, axis=0)\n",
        ")\n",
        "print(f\"test_auc: {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPvk_Jl4N6FP",
        "outputId": "78e8c888-79c8-4c1f-9eef-523edc587d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation results:\n",
            "mean_train_auc: 0.9796 ± 0.0063\n",
            "mean_val_auc: 0.9474 ± 0.0300\n",
            "\n",
            "Ensembling results on test set:\n",
            "test_auc: 0.8855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Optional\n",
        "import random\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import set_seed as set_seed_hf\n",
        "from transformers import AutoImageProcessor\n",
        "\n",
        "dataset_name = \"/home/rakib/data/NCT-CRC-HE-100K-NONORM\"\n",
        "# You can change the dataset name above if you wish to finetune the model on your own dataset.\n",
        "\n",
        "\n",
        "# We set a seed globally for data loading and training\n",
        "SEED = 123\n",
        "\n",
        "def set_seed(seed: Optional[int] = None):\n",
        "    \"\"\"Set all seeds to make results reproducible (deterministic mode).\n",
        "    When seed is None, disables deterministic mode.\n",
        "    Credits @BramVanroy\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        set_seed_hf(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "dataset = load_dataset(\"imagefolder\", data_dir=\"/home/rakib/data/NCT-CRC-HE-100K-NONORM\", cache_dir=cache_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "f74e716f447c4c7e808cfed801a70329",
            "39e3cc882eec41d293edcc6def7a6c19",
            "1753799df4944f629ab67ff2393d53ea",
            "b70bf35c093947faa08af2524b9c76c5",
            "44bae7b082744836a4358a75fcf3a49c",
            "9a8d20a943f34b0c9ce08fd93062e29c",
            "2004a5ffd8614995baecd05f8231d327",
            "c1f7ce8a424f465d9f0d8cfa584e3edd",
            "8a84f6379cf241989b79430f8a730a99",
            "edaf8964257a4c4b847fdc33627ebfdc",
            "d1669ce6f92843ea966a4a8690c5fa7f"
          ]
        },
        "id": "cRA5OJpPOmk9",
        "outputId": "a4375218-5437-4ddc-ddb6-e98e7753edab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/100000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f74e716f447c4c7e808cfed801a70329"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug dataset properties\n",
        "print(dataset.keys())\n",
        "print(dataset.items())\n",
        "print(dataset.unique)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbtPnsmnH8jb",
        "outputId": "6ce1371c-d79b-4ce5-9810-04cb3e604553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['train'])\n",
            "dict_items([('train', Dataset({\n",
            "    features: ['image', 'label'],\n",
            "    num_rows: 100000\n",
            "}))])\n",
            "<bound method DatasetDict.unique of DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['image', 'label'],\n",
            "        num_rows: 100000\n",
            "    })\n",
            "})>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nct_data = dataset['train']\n",
        "\n",
        "# Get labels and images\n",
        "labels = nct_data['label']\n",
        "images = nct_data['image']"
      ],
      "metadata": {
        "id": "RnHxU04FSovQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This strategy doesnot take into account the class imbalance issue\n",
        "\n",
        "# Define the number of samples you want to randomly select\n",
        "num_samples = 1000  # Change this number to your desired value\n",
        "\n",
        "# Randomly sample from the dataset according to the number of samples\n",
        "random_indices = random.sample(range(len(labels)), num_samples)\n",
        "\n",
        "# Extract sampled labels and images\n",
        "sampled_labels = [labels[i] for i in random_indices]\n",
        "sampled_images = [images[i] for i in random_indices]\n",
        "\n",
        "# Strategy to solve the class imbalance issue\n",
        "'''\n",
        "from collections import defaultdict\n",
        "\n",
        "# Define the number of samples you want to randomly select\n",
        "num_samples_per_class = 10  # Change this number to your desired value per class\n",
        "\n",
        "# Initialize a dictionary to store sampled indices for each class\n",
        "class_indices = defaultdict(list)\n",
        "\n",
        "# Map class names to class labels\n",
        "class_name_to_label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "# Collect indices for each class\n",
        "for i, label in enumerate(labels):\n",
        "    class_name = label2id[label]\n",
        "    class_label = class_name_to_label[class_name]\n",
        "    class_indices[class_label].append(i)\n",
        "\n",
        "# Randomly sample from each class\n",
        "sampled_indices = []\n",
        "for class_label, indices in class_indices.items():\n",
        "    sampled_indices.extend(random.sample(indices, num_samples_per_class))\n",
        "\n",
        "# Extract sampled labels and images\n",
        "sampled_labels = [labels[i] for i in sampled_indices]\n",
        "sampled_images = [images[i] for i in sampled_indices]\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dir3QEVuV8Np",
        "outputId": "9e5ea5c3-8745-4cba-84c2-4261d13879b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom collections import defaultdict\\n\\n# Define the number of samples you want to randomly select\\nnum_samples_per_class = 10  # Change this number to your desired value per class\\n\\n# Initialize a dictionary to store sampled indices for each class\\nclass_indices = defaultdict(list)\\n\\n# Map class names to class labels\\nclass_name_to_label = {v: k for k, v in label2id.items()}\\n\\n# Collect indices for each class\\nfor i, label in enumerate(labels):\\n    class_name = label2id[label]\\n    class_label = class_name_to_label[class_name]\\n    class_indices[class_label].append(i)\\n\\n# Randomly sample from each class\\nsampled_indices = []\\nfor class_label, indices in class_indices.items():\\n    sampled_indices.extend(random.sample(indices, num_samples_per_class))\\n\\n# Extract sampled labels and images\\nsampled_labels = [labels[i] for i in sampled_indices]\\nsampled_images = [images[i] for i in sampled_indices]\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the percentage for the validation set\n",
        "split_percentage = 0.5\n",
        "\n",
        "# Split the sampled data into train and validation sets\n",
        "train_labels, val_labels, train_images, val_images = train_test_split(sampled_labels, sampled_images, test_size=split_percentage)\n",
        "\n",
        "# Strategy to solve the class imbalance issue\n",
        "'''\n",
        "# Split the sampled data into train and validation sets\n",
        "train_indices, val_indices = train_test_split(sampled_indices, test_size=split_percentage, stratify=sampled_labels)\n",
        "\n",
        "# Because it's a list function, this step is necessary:\n",
        "\n",
        "# Extract labels and images for train and validation sets\n",
        "train_labels = [labels[i] for i in train_indices]\n",
        "train_images = [images[i] for i in train_indices]\n",
        "\n",
        "val_labels = [labels[i] for i in val_indices]\n",
        "val_images = [images[i] for i in val_indices]\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTZLSMPPIXqe",
        "outputId": "a96da713-ba3c-49b9-d3f0-2d9262201c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Split the sampled data into train and validation sets\\ntrain_indices, val_indices = train_test_split(sampled_indices, test_size=split_percentage, stratify=sampled_labels)\\n\\n# Because it's a list function, this step is necessary:\\n\\n# Extract labels and images for train and validation sets\\ntrain_labels = [labels[i] for i in train_indices]\\ntrain_images = [images[i] for i in train_indices]\\n\\nval_labels = [labels[i] for i in val_indices]\\nval_images = [images[i] for i in val_indices]\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and validation datasets\n",
        "train_dataset = {'image': train_images, 'label': train_labels}\n",
        "val_dataset = {'image': val_images, 'label': val_labels}\n",
        "\n",
        "# Print the number of samples in each set\n",
        "print(f\"Number of samples in the train set: {len(train_labels)}\")\n",
        "print(f\"Number of samples in the validation set: {len(val_labels)}\")"
      ],
      "metadata": {
        "id": "f_QmHXK0S-hD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8ebb1f-ea43-440a-9464-3990713ca78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the train set: 500\n",
            "Number of samples in the validation set: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# From the NCT-CRC 999 samples, we create train and validation sets of 500 images each\n",
        "\n",
        "# test_dataset_path = \"/home/rakib/data/CRC-VAL-HE-7K\"\n",
        "\n",
        "# Test dataset contains 7,180 images\n",
        "test_dataset = load_dataset(\"imagefolder\", data_dir=\"/home/rakib/data/CRC-VAL-HE-7K\", cache_dir=cache_dir)\n",
        "print(f\"Training dataset size: {len(train_dataset)}\\n\" f\"Validation dataset size: {len(val_dataset)}\\n\" f\"Test dataset size: {len(test_dataset)}\\n\")"
      ],
      "metadata": {
        "id": "mQmdnZgjIg9R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "8ff42b5332b8452da3404c1485667f07",
            "3f455feee0b845f3a2c7f20afb7a1127",
            "12912d2262b54d16b6c9f93c26197978",
            "0fc61da438994b6e8af0c9608a1b7681",
            "8295e260fd8b404b8ad4f459f1f7fe25",
            "684089a185794b8b8664f2100d1f1127",
            "38fd34e0c8814e048a72ee1414f60f81",
            "4b259235555e4cad9c0fca393e79af06",
            "d5c02905d9a64ab0bcc5e2fcb306ffaf",
            "661b933330de482fb9a48aef8061de7b",
            "0c75697ac16f4d1798d93bb88ce6b609"
          ]
        },
        "outputId": "0ee6d506-d905-49b1-9014-4fb686e26b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/7180 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ff42b5332b8452da3404c1485667f07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 2\n",
            "Validation dataset size: 2\n",
            "Test dataset size: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.unique"
      ],
      "metadata": {
        "id": "ocAh5ZqIMliv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9fd4b3-9da9-4002-acc2-3ade1396bd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DatasetDict.unique of DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 7180\n",
              "    })\n",
              "})>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Create train and validation datasets\n",
        "train_dataset = Dataset.from_dict({'image': train_images, 'label': train_labels})\n",
        "val_dataset = Dataset.from_dict({'image': val_images, 'label': val_labels})\n",
        "test_dataset = Dataset.from_dict({'image': test_dataset['train']['image'], 'label': test_dataset['train']['label']})\n",
        "print(f\"Training dataset size: {len(train_dataset)}\\n\" f\"Validation dataset size: {len(val_dataset)}\\n\" f\"Test dataset size: {len(test_dataset)}\\n\")"
      ],
      "metadata": {
        "id": "NdwekmnlmZ4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809b0d49-fe2f-4f03-ba27-f4afc1b9baa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 500\n",
            "Validation dataset size: 500\n",
            "Test dataset size: 7180\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_processor = AutoImageProcessor.from_pretrained(\"owkin/phikon\")\n",
        "print(image_processor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dX39lHgvTuV",
        "outputId": "21b4d4f7-1dca-4507-e499-009e623907b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViTImageProcessor {\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.485,\n",
            "    0.456,\n",
            "    0.406\n",
            "  ],\n",
            "  \"image_processor_type\": \"ViTImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.229,\n",
            "    0.224,\n",
            "    0.225\n",
            "  ],\n",
            "  \"resample\": 2,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"height\": 224,\n",
            "    \"width\": 224\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any\n",
        "from torchvision.transforms import (\n",
        "    CenterCrop,\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomResizedCrop,\n",
        "    Resize,\n",
        "    ToTensor,\n",
        ")\n",
        "\n",
        "# ImageNet normalization\n",
        "normalize = Normalize(\n",
        "    mean=image_processor.image_mean,\n",
        "    std=image_processor.image_std\n",
        ")\n",
        "\n",
        "# train transforms = random crop, resizing to 224x224, random flip, normalization\n",
        "train_transforms = Compose(\n",
        "    [\n",
        "        RandomResizedCrop(image_processor.size[\"height\"]),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "# val transforms = resizing to 224x224, normalization\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        Resize(image_processor.size[\"height\"]),\n",
        "        CenterCrop(image_processor.size[\"height\"]),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "8uYOk70xvknM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "def preprocess_train(example_batch: dict[str, Any]) -> dict[str, Any]:\n",
        "    \"\"\"Apply ``train_transforms`` across a batch.\"\"\"\n",
        "    example_batch[\"pixel_values\"] = [\n",
        "        train_transforms(image) for image in example_batch[\"image\"]\n",
        "    ]\n",
        "    return example_batch\n",
        "\n",
        "\n",
        "def preprocess_val(example_batch: dict[str, Any]) -> dict[str, Any]:\n",
        "    \"\"\"Apply ``val_transforms`` across a batch.\"\"\"\n",
        "    example_batch[\"pixel_values\"] = [\n",
        "        val_transforms(image) for image in example_batch[\"image\"]\n",
        "    ]\n",
        "    return example_batch\n",
        "'''\n",
        "\n",
        "# Modified to avoid type error due to python3.8\n",
        "def preprocess_train(example_batch: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Apply ``train_transforms`` across a batch.\"\"\"\n",
        "    example_batch[\"pixel_values\"] = [\n",
        "        train_transforms(image) for image in example_batch[\"image\"]\n",
        "    ]\n",
        "    return example_batch\n",
        "\n",
        "\n",
        "def preprocess_val(example_batch: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Apply ``val_transforms`` across a batch.\"\"\"\n",
        "    example_batch[\"pixel_values\"] = [\n",
        "        val_transforms(image) for image in example_batch[\"image\"]\n",
        "    ]\n",
        "    return example_batch\n",
        "\n",
        "# Apply the transformations\n",
        "train_dataset.set_transform(preprocess_train)\n",
        "val_dataset.set_transform(preprocess_val)\n",
        "test_dataset.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "TevxBST8v7kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "# Labels from our dataset\n",
        "label2id = {\n",
        "    '0': \"ADI\",\n",
        "    '1': \"BACK\",\n",
        "    '2': \"DEB\",\n",
        "    '3': \"LYM\",\n",
        "    '4': \"MUC\",\n",
        "    '5': \"MUS\",\n",
        "    '6': \"NORM\",\n",
        "    '7': \"STR\",\n",
        "    '8': \"TUM\"\n",
        "}\n",
        "id2label = {v: k for (k, v) in label2id.items()}\n",
        "\n",
        "# Load the model\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"owkin/phikon\",\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=False,\n",
        "    cache_dir=cache_dir,\n",
        ")\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "A4RaTMFQyc-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We also create a version of Phikon where the model is kept frozen and only the classifier head is trained (0.01% of the training parameters).\n",
        "from copy import deepcopy\n",
        "\n",
        "frozen_model = deepcopy(model)\n",
        "\n",
        "for name, param in frozen_model.named_parameters():\n",
        "     if not name.startswith(\"classifier.\"):\n",
        "        param.requires_grad = False\n",
        "print_trainable_parameters(frozen_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9rR_rtCyy2y",
        "outputId": "081f39b1-5614-4081-c9d9-997853fb77e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 6921 || all params: 85805577 || trainable%: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA fine-tuning only requires 0.70% of the original trainable parameters!\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "\n",
        "# load and configure LoRA from Hugging Face peft library\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    modules_to_save=[\"classifier\"],\n",
        ")\n",
        "lora_model = get_peft_model(model, config)\n",
        "print_trainable_parameters(lora_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69YnZzFzzI1Z",
        "outputId": "98210a95-b5bd-4458-a72d-986c01af2daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 596745 || all params: 86402322 || trainable%: 0.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Config.\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import evaluate\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# LoRA configuration\n",
        "\n",
        "batch_size = 24\n",
        "args = TrainingArguments(\n",
        "    \"phikon-finetuned-nct-1k\",\n",
        "    remove_unused_columns=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-3,\n",
        "    gradient_accumulation_steps=1,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    fp16=True,\n",
        "    seed=SEED,\n",
        "    num_train_epochs=10,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",  # dataset is roughly balanced\n",
        "    push_to_hub=False,\n",
        "    label_names=[\"labels\"],\n",
        ")\n",
        "\n",
        "# Metric configuration\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred: np.ndarray) -> float:\n",
        "    \"\"\"Computes accuracy on a batch of predictions.\"\"\"\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
        "\n",
        "# Inputs generation for training\n",
        "\n",
        "# Modified to avoid type error (def collate_fn(examples) -> dict[str, torch.Tensor]:)\n",
        "def collate_fn(examples) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"Create the inputs for LoRA from an example in the dataset.\"\"\"\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "# Here is the final trainer\n",
        "trainer_lora = Trainer(\n",
        "    model=lora_model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=image_processor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf925P7EzN3Y",
        "outputId": "74c305e0-4d5c-4735-e938-019b1c43223d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "import warnings\n",
        "\n",
        "from transformers.utils import logging\n",
        "\n",
        "\n",
        "# We display the accuracy on the test set at the end\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "    train_results_lora = trainer_lora.train()\n",
        "    metrics_lora = trainer_lora.evaluate(test_dataset)\n",
        "    trainer_lora.log_metrics(\"Fine-tuned model: VAL-CRC-7K\", metrics_lora)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "FANrihF4zw2_",
        "outputId": "d12c4a03-e2af-477e-f07f-98dd81445316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [210/210 00:36, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.084500</td>\n",
              "      <td>0.344558</td>\n",
              "      <td>0.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.038000</td>\n",
              "      <td>0.255675</td>\n",
              "      <td>0.956000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>0.196676</td>\n",
              "      <td>0.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.199400</td>\n",
              "      <td>0.218456</td>\n",
              "      <td>0.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.242600</td>\n",
              "      <td>0.205281</td>\n",
              "      <td>0.974000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.711700</td>\n",
              "      <td>0.197085</td>\n",
              "      <td>0.976000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>0.226190</td>\n",
              "      <td>0.974000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.053800</td>\n",
              "      <td>0.243062</td>\n",
              "      <td>0.968000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.215306</td>\n",
              "      <td>0.966000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.229913</td>\n",
              "      <td>0.968000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-21 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-42 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-63 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-84 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-105 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-126 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-147 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-168 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-189 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-210 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Fine-tuned model: VAL-CRC-7K metrics *****\n",
            "  epoch                   =       10.0\n",
            "  eval_accuracy           =     0.8703\n",
            "  eval_loss               =     0.7006\n",
            "  eval_runtime            = 0:00:23.42\n",
            "  eval_samples_per_second =    306.465\n",
            "  eval_steps_per_second   =     12.805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We now do the same training thing fully-frozen Phikon.\n",
        "\n",
        "We observe up to a +2 increase in multi-class accuracy using LoRA fine-tuning, for only 30 seconds of extra training cost.\n"
      ],
      "metadata": {
        "id": "FMFWEaC86k_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer_frozen = Trainer(\n",
        "    frozen_model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=image_processor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        ")\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "    train_results_frozen = trainer_frozen.train()\n",
        "    metrics_frozen = trainer_frozen.evaluate(test_dataset)\n",
        "    trainer_frozen.log_metrics(\"Frozen model: VAL-CRC-7K\", metrics_frozen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "pmrFmOx36Yfy",
        "outputId": "76c1dac1-b44a-4c96-f981-1186bebf092a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [210/210 00:26, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.021600</td>\n",
              "      <td>0.205745</td>\n",
              "      <td>0.962000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.031700</td>\n",
              "      <td>0.208488</td>\n",
              "      <td>0.972000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.245477</td>\n",
              "      <td>0.962000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.153000</td>\n",
              "      <td>0.301633</td>\n",
              "      <td>0.958000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.007800</td>\n",
              "      <td>0.279823</td>\n",
              "      <td>0.966000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.518400</td>\n",
              "      <td>0.228675</td>\n",
              "      <td>0.968000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.218700</td>\n",
              "      <td>0.217447</td>\n",
              "      <td>0.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>0.242014</td>\n",
              "      <td>0.964000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.230358</td>\n",
              "      <td>0.964000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.226605</td>\n",
              "      <td>0.966000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-21 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-42 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-63 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-84 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-105 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-126 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-147 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-168 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-189 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory phikon-finetuned-nct-1k/checkpoint-210 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:22]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Frozen model: VAL-CRC-7K metrics *****\n",
            "  epoch                   =       10.0\n",
            "  eval_accuracy           =     0.8435\n",
            "  eval_loss               =     0.5429\n",
            "  eval_runtime            = 0:00:22.38\n",
            "  eval_samples_per_second =    320.777\n",
            "  eval_steps_per_second   =     13.403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizing features**\n",
        "\n",
        "We can then visualize the features. We do this for a frozen model as well as LoRA in order to examine the differences in the embeddings."
      ],
      "metadata": {
        "id": "n_yPmdQv6yhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib.axes._axes import Axes\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# First we define a set of functions to\n",
        "# 1) get the embeddings from the models\n",
        "# 2) compute the 2D projections using the t-SNE algorithm\n",
        "# 3) visualize these projections using ``seaborn```\n",
        "\n",
        "def get_raw_embeddings(model, dataset, use_fp16: bool = True):\n",
        "    \"\"\"Retrieve tiles embeddings from a model equipped with a classifier head.\"\"\"\n",
        "    embeddings = []\n",
        "    for pixel_values in tqdm(dataset[\"pixel_values\"]):\n",
        "        image = pixel_values.unsqueeze(0).to(\n",
        "            \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
        "            torch.float16 if use_fp16 else torch.float32\n",
        "          )\n",
        "        output = model(image, output_hidden_states=True)\n",
        "        _embeddings = output.hidden_states[-1][:, 0, :].detach().cpu().numpy()\n",
        "        embeddings.append(_embeddings)\n",
        "    return np.concatenate(embeddings, axis=0)\n",
        "\n",
        "\n",
        "def get_tsne_embeddings(raw_embeddings: np.ndarray, **kwargs):\n",
        "    \"\"\"Compute 2-dimensional tsne projections from raw embeddings.\"\"\"\n",
        "    tsne = TSNE(**kwargs)\n",
        "    tsne_embeddings = tsne.fit_transform(raw_embeddings)\n",
        "    tsne_embeddings = pd.DataFrame(tsne_embeddings, columns=[\"tsne-1\", \"tsne-2\"])\n",
        "    tsne_embeddings[\"Tissue type\"] = test_subset_labels\n",
        "    tsne_embeddings[\"Tissue type\"] = tsne_embeddings[\"Tissue type\"].astype(str).replace(label2id)\n",
        "    return tsne_embeddings\n",
        "\n",
        "def plot_tsne_embeddings(tsne_embeddings: np.ndarray, title: str, ax: Axes):\n",
        "    \"\"\"Plot tsne embeddings in the 2D space.\"\"\"\n",
        "    sns.scatterplot(\n",
        "        x=\"tsne-1\", y=\"tsne-2\",\n",
        "        hue=\"Tissue type\",\n",
        "        palette=sns.color_palette(\"hls\", 9),\n",
        "        data=tsne_embeddings,\n",
        "        legend=\"full\",\n",
        "        alpha=0.3,\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(title)\n",
        "    return ax"
      ],
      "metadata": {
        "id": "1VxVSXCS6tMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We consider a subset of 1,000 images from the original test set."
      ],
      "metadata": {
        "id": "Tb-Z8VFC7uMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_size = 7000\n",
        "test_subset = test_dataset[:subset_size]\n",
        "# Randomly sample from the dataset according to the number of samples\n",
        "# test_data = test_dataset\n",
        "\n",
        "# Get labels and images\n",
        "# subset_labels = test_data['label']\n",
        "# subset_images = test_data['image']\n",
        "# random_test_indices = random.sample(range(len(labels)), subset_size)\n",
        "\n",
        "# Extract sampled labels and images\n",
        "# subset_labels = [labels[i] for i in random_indices]\n",
        "# subset_images = [images[i] for i in random_indices]\n",
        "\n",
        "\n",
        "print(f\"Computing LORA and frozen models embeddings on 7168 test images...\")\n",
        "test_dataset_embeddings_lora = get_raw_embeddings(\n",
        "    model=lora_model, dataset=subset_images\n",
        ")\n",
        "test_dataset_embeddings_frozen = get_raw_embeddings(\n",
        "    model=frozen_model, dataset=subset_images\n",
        ")\n",
        "test_dataset_labels = np.array(subset_labels)\n",
        "\n",
        "print(\"Computing tsne projections...\")\n",
        "tsne_embeddings_lora = get_tsne_embeddings(\n",
        "    test_dataset_embeddings_lora, n_components=2\n",
        ")\n",
        "tsne_embeddings_frozen = get_tsne_embeddings(\n",
        "    test_dataset_embeddings_frozen, n_components=2\n",
        "  )"
      ],
      "metadata": {
        "id": "3U77O09K7jtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The differences between the LoRA fine-tuned and frozen models are small due to the highly separable nature of NCT-CRC prediction task (different tissues can be distinguished easily by the naked eye). However, we notice that LoRA fine-tuning allows to better disentangle clusters such as Lymphocytes (Yellow) and Tumor (red), which can play a significant role in cancer diagnosis."
      ],
      "metadata": {
        "id": "5xJCjl4575wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Plotting in 2 dimensions.\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "axes[0] = plot_tsne_embeddings(\n",
        "    tsne_embeddings_lora, title=\"Lora embeddings\", ax=axes[0]\n",
        ")\n",
        "axes[1] = plot_tsne_embeddings(\n",
        "    tsne_embeddings_frozen, title=\"Frozen embeddings\", ax=axes[1]\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iJ1gxNxc7ysh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDDqFK8q73U3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}